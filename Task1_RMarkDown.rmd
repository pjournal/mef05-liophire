---
title: "**BDA-503 Week 1 - RMarkdown Task**"
author: "_Emirhan Şahin_"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
    html_notebook:
        toc: true
        toc_depth: 2
        toc_float: true
---
<br>
<style>
#TOC {
    color: #404040;
    font-size: 13px;
    border-color: #000000;
    font-family: -apple-system, system-ui, BlinkMacSystemFont, "Segoe UI", Roboto, Ubuntu;
}
h1.title {
    color: #404040;
    font-family: -apple-system, system-ui, BlinkMacSystemFont, "Segoe UI", Roboto, Ubuntu;
}
h4.author {
    color: #404040;
    font-size: 12px;
    font-family: -apple-system, system-ui, BlinkMacSystemFont, "Segoe UI", Roboto, Ubuntu;
}
h4.date {
    color: #404040;
    font-size: 12px;
    font-family: -apple-system, system-ui, BlinkMacSystemFont, "Segoe UI", Roboto, Ubuntu;
}
body {
    color: #696969;
    font-family: -apple-system, system-ui, BlinkMacSystemFont, "Segoe UI", Roboto, Ubuntu;
    background-color: #F5F5F5;
    font-size: 13px;
</style>

# **Personal Information**
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My name is **Emirhan Şahin**. I was born in [Bursa](https://en.wikipedia.org/wiki/Bursa), in 1998 and lived there for the first 18 years of my life.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I graduated from [The Faculty of Economics in English](https://ingiktisat-iktisat.istanbul.edu.tr/en) at [Istanbul University](https://www.istanbul.edu.tr/en/_) in August 2020. During my bachelor's degree, I participated in the Erasmus programme to promote myself in terms of sociability and a better vision for the world. I went to [Barcelona](https://en.wikipedia.org/wiki/Barcelona), one of my favorite countries, the most beautiful city in Spain. I also started to work as a cashier in [Zara, Inditex](https://www.inditex.com/). Just in 3 months, I got promoted to accountant position then to the administrative services responsible position. After working there for almost 3 years, I quit my job to complete my degree.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Upon completing my bachelor’s degree, I moved to [Izmir](https://en.wikipedia.org/wiki/İzmir) in the summer of 2020 for a job. In which I was able to improve myself in so many ways. I also had a chance to earn money while doing something I love, using computers and other technologies. Therefore, I learned applications like [Photoshop](https://www.adobe.com/products/photoshop.html), [Corel](https://www.corel.com/en/), and [Google Ads](https://ads.google.com/home/) in a short time, on my own. I was able to practice my knowledge in [Microsoft Office](https://www.office.com/), various accounting and management programs. That is also the way that I met **data science and machine learning**. So I started to learn about programming and data science on my own, but I have decided that I need to study professionally, therefore, and get a postgraduate program in order to be ready for the industry. For this purpose, I began my master's degree in [Big Data Analytics](https://bda.mef.edu.tr/en#gsc.tab=0) at [MEF University](https://www.mef.edu.tr/en#gsc.tab=0) in September 2021.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I am focusing on professionalizing the theoretical knowledge I received during my academic career. I hope to prove all the knowledge I have at a company that utilizes machine learning and big data. I would love to work on real-life artificial intelligence and machine learning projects.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For further information, you can take a look at my [LinkedIn](https://www.linkedin.com/in/emirhan-sahin/) page or ask me on [Twitter](https://twitter.com/liophire).
<br>
<br>

# **Tree-Based Machine Learning for Insurance Pricing**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_This part includes a review and summary of a [R Consortium video.](https://www.youtube.com/watch?v=z1AlNGXGz9A)_
<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I have chosen this video to review because the topic is closely related to the real world and the main focus is on [big data](https://en.wikipedia.org/wiki/Big_data) and [machine learning](https://en.wikipedia.org/wiki/Machine_learning).
<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The presenter first starting to talk about the methods and formulas they use to assess the [price of a premium](https://www.investopedia.com/terms/i/insurance-premium.asp). Then he explains the goal of the presentation. He states that the [Generalized Linear Model](https://en.wikipedia.org/wiki/Generalized_linear_model) by [J.Nelder](https://en.wikipedia.org/wiki/John_Nelder) and [R.Wedderburn](https://en.wikipedia.org/wiki/Robert_Wedderburn_(statistician)) is a widely used model in classical premium calculations. He later continues to explain the machine learning methods and parameters that are used. He tweaks the way frequency and severity are calculated in the [Generalized Linear Model](https://en.wikipedia.org/wiki/Generalized_linear_model) by replacing [count distribution](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119097013.app1) in frequency with [Poisson deviance](https://peijin.medium.com/the-poisson-deviance-for-regression-d469b56959ce) and [skewed function](https://www.statisticshowto.com/probability-and-statistics/skewed-distribution/) in severity with [Gamma deviance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_gamma_deviance.html#:~:text=Gamma%20deviance%20is%20equivalent%20to,variable%2C%20and%20measures%20relative%20errors.&text=Ground%20truth%20(correct)%20target%20values,Requires%20y_true%20>%200.) as loss function.
<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the second half of the video, the presenter illustrates the results of the new ML techniques and compares them with the classical methods. He states even though both of the classical methods are better than 2 of the new ML technique, [Gradient Boosting Machine](https://en.wikipedia.org/wiki/Gradient_boosting) returns the most precise results out of all 5 tests. Later he continues to demonstrate the results and graphs of the tests and to explain how profitable it can be once the company implements GBM technique.
<br>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the end, he concludes by summarizing the pros and cons of using machine learning techniques.
<br>
<br>

# **Interesting R Posts**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_In this part, I will review and summarize 3 R posts._
<br>

## &nbsp;&nbsp;&nbsp; **1. Improving a Visualization**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_This is a summary of [Improving a Visualization](https://jcarroll.com.au/2021/07/02/improving-a-visualization/) by [Jonathan Carroll](https://github.com/jonocarroll)_
<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Visualization is a crucial way to make sense of the trillions of rows of data generated every day. Data visualization helps to tell stories by curating data into a form easier to understand, highlighting the trends and outliers. As data scientists and analysts, we  will often in our career face an issue that requires visualization, therefore, it is important to learn alternative ways to visualize. Exactly  in this blog, the blogger demonstrates alternative visualization techniques for [streaming services market share, comparing 2020 to 2021](https://www.reddit.com/r/dataisbeautiful/comments/mtld5f/oc_us_streaming_services_market_share_2020_vs_2021/).

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; He found that the [original visualization](https://www.reddit.com/r/dataisbeautiful/comments/mtld5f/oc_us_streaming_services_market_share_2020_vs_2021/gv0bv4j/?utm_source=share&utm_medium=web2x&context=3) is built on PowerPoint but he was going to reproduce it in R. First he gathered the [data](https://www.thewrap.com/netflix-streaming-us-market-share-chart/) then built a simple barplot using _[ggplot2](https://ggplot2.tidyverse.org/)_. He continued to edit the barplot by changing the font, colors and adding the logos.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; After achieving the original visualization with better colors and font, he proceeds to illustrate the same data on the [pie chart](https://en.wikipedia.org/wiki/Pie_chart). And then on the [horizontal bar graph](https://www.splashlearn.com/math-vocabulary/geometry/horizontal-bar-graph). Even though the prior visualizations does the job to show the current and previous market shares, in order to get a better idea about the one-year changes, loss and growth, he centered the 2020 percentages and demonstrated the differences with 2021. The blogger continues to explain the data on the [dumbbell plot](https://www.business-science.io/r/2021/08/12/ggalt-dumbbell-plots-ggplot2.html#:~:text=What%20is%20a%20Dumbbell%20Plot,(think%20start%20and%20finish).), aiming to show the separation between the two values. Even animates the changes between the two years. But the one that is interesting to me was the [alluvial plot](https://en.wikipedia.org/wiki/Alluvial_diagram). Because it easily illustrated the transitions between service providers.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This blog helps us to understand **how easy it is to code and to demonstrate the alternative ways of visualization in R**.
<br>
<br>

## &nbsp;&nbsp;&nbsp; **2. 5 Ways to Subset a Data Frame in R**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_This is a review of [5 Ways to Subset a Data Frame in R](https://rveryday.wordpress.com/2016/11/29/5-ways-to-subset-a-data-frame-in-r/) by [Douglas E. Rice](https://www.r-bloggers.com/author/douglas-e-rice/)_
<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [Subsetting a data frame](https://www.statmethods.net/management/subset.html) is the process of selecting [a set of rows and columns from the data frame](https://csharpcorner-mindcrackerinc.netdna-ssl.com/article/r-data-frame-operations-adding-rows-removing-rows-and-merging-two-data-frame/Images/UpdatedImage/Added%20By%20add_row.JPG). Subsetting is very useful because we often want to perform operations on subsets of our data, especially if it is [big data](https://en.wikipedia.org/wiki/Big_data#:~:text=Big%20data%20is%20a%20field,traditional%20data-processing%20application%20software.&text=Big%20data%20was%20originally%20associated,volume%2C%20variety%2C%20and%20velocity.). Also one of the important purposes of subsetting is to save [bandwidth](https://en.wikipedia.org/wiki/Bandwidth_(computing)) on the network and [storage space](https://en.wikipedia.org/wiki/Computer_data_storage) on the computer.

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **1.**  The blogger at first explaining **the most basic way of subsetting a data frame in R**. This method is done by using **square brackets**.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ![Subset](https://cdn.guru99.com/images/r_programming/032918_1452_RDataFrames1.png)\

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Then, he continues with a hypothetical scenario. And retrieving the required data from the data frame by subsetting. With that subsetted data, he creates a new data frame.

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **2.**  In the second method, he mentions that in order to get the required data in the same data frame we can easily omit the unnecessary data. It is quite similar to the first method but instead, he uses **"-"** sign before [vector](https://www.tutorialspoint.com/r/r_vectors.htm) function.
```{r, eval = FALSE}
subtracting_data_frame <- education[-c(1:9,22:50),-c(1,3:5)]
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **3.**  Often we work on a large data set that it is not possible to count row and column numbers. In that case the blogger suggests to use the code below :
```{r, eval = FALSE}
new_data_frame <- education[which(education$Region == 2),names(education) %in% c("State","Minor.Population","Education.Expenditures")]
```
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In this method, by using the [which()](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/which) function we are able to get the returns the indices where the Region column of the education data from is 2. By using the [%in%](https://www.datasciencemadesimple.com/in-operator-in-r/) operator he retrieved the columns of the subset on the names of the education data frame.

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **4.**  In the next method, he explains an easier way by using [subset()](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/subset) built-in function in R.
```{r, eval = FALSE}
easier_data_frame <- subset(education, Region == 2, select = c("State","Minor.Population","Education.Expenditures"))
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **5.**  He states that the last method is **the most useful in manipulating data** once you get a grasp of it. This method is not initially included basic R, therefore, we need to download the _[dplyr](https://dplyr.tidyverse.org/)_ package.
```{r, eval = FALSE}
install.packages("dplyr")
library(dplyr)
dplyr_data_frame <- select(filter(education, Region == 2),c(State,Minor.Population:Education.Expenditures))
```
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Once we’ve downloaded dplyr, we use [filter](https://dplyr.tidyverse.org/reference/filter.html) and [select](https://dplyr.tidyverse.org/reference/filter.html) functions in the package. Even though this method requires an external package we can see that, it is the easier and faster way to achieve the required output.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This blog helps us to understand **multiple ways of subsetting in R in different situations**.
<br>
<br>

## &nbsp;&nbsp;&nbsp; **3. How to Remove Outliers in R**
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;_This is a summary of [How to Remove Outliers in R](https://www.programmingr.com/content/remove-outliers-in-r/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+ProgrammingR+%28Programming+R%29) by [Syed A. Hadi](https://www.programmingr.com/content/author/syed/)_
<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An [outlier](https://en.wikipedia.org/wiki/Outlier) is a data point that differs from other data points in a data set. Even though it sounds easy, determining what is or isn't an outlier is pretty subjective, depending on the study. In this blog, the blogger goes into details about identifying, visualizing and removing outliers from a dataset. [Removing an outlier](https://humansofdata.atlan.com/2018/03/when-delete-outliers-dataset/) is crucial for data analysis since it can dramatically affect the model, the plot or the data output.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **1.  Looking at Outliers in R**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Statisticians use and prefer different ways to locate the outliers in a dataset. The most common methods include the [Z-score](https://www.statisticshowto.com/probability-and-statistics/z-score/) method and the [Interquartile Range (IQR)](https://www.statisticshowto.com/probability-and-statistics/interquartile-range/) method. In this blog, the blogger uses the IQR method. In this method, outliers are considered points that are **below [Q1 - (1.5)IQR]** or **above [Q3 + (1.5)IQR]**.

![interquartile](https://www.statology.org/wp-content/uploads/2021/01/iqrOutlier1.png)\

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; He is starting with loading ___`warpbreaks`___ built-in dataset on R using [the data function](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/data).
```{r}
data("warpbreaks")
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **2. Visualizing Outliers in R**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Secondly, he is creating the [boxplot](https://en.wikipedia.org/wiki/Box_plot) to identify the outliers.
```{r}
boxplot(warpbreaks)$out
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **3. Finding Outliers – Statistical Methods**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Generally, the visualization method is considered easy but it can become a real burden for the system, therefore,  we will use statistical methods a lot in big data analytics. He is using the [quantile()](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/quantile) function to find the 25th and the 75th percentile of the dataset, and the [IQR()](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/IQR) function which gives him the difference of the 75th and 25th percentiles. Then, the cut-off ranges beyond which all data points are outliers.
```{r, eval = FALSE}
Q <- quantile(warpbreaks$breaks, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(warpbreaks$breaks)
up <-  Q[2]+1.5*iqr # Upper Range
low<- Q[1]-1.5*iqr # Lower Range
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **3. Eliminating Outliers in R**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Using the [subset()](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/subset) function, he is extracting the data points that is **not outliers**. Then visualizing it on boxplot.
```{r, eval = FALSE}
eliminated <- subset(warpbreaks, warpbreaks$breaks > (Q[1] - 1.5*iqr) & warpbreaks$breaks < (Q[2]+1.5*iqr))
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; R also has other ways of removing outliers, one of them done by using the [boxplot()](https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/boxplot) function to identify the outliers and the [which()](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/which) function to find and remove them from the dataset.
```{r, eval = FALSE}
boxplot(warpbreaks$breaks, plot=FALSE)$out # identifying the outliers
outliers <- boxplot(warpbreaks$breaks, plot=FALSE)$out # saving the outliers in a vector
x <-warpbreaks
x <- x[-which(x$breaks %in% outliers),]
```

<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Even though, it requires a little bit more R knowledge, this is maybe **the more efficient way to remove outliers in R**.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This blog explains us **why and how to remove outliers in R**.
<br>
<br>
<br>

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;___Thanks for reading...___
<br>
<br>
![RMarkdown](https://www.marathonus.com/media/2366/using-r-markdown-to-share-analysis-s.jpg?quality=80)\